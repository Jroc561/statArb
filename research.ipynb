{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Statistical Arbitrage - Pair Trading Strategyimport pandas as pd\n",
    "import numpy as np\n",
    "from os import getenv\n",
    "from binance.client import Client # pip install python-binance\n",
    "from binance.websockets import BinanceSocketManager\n",
    "from twisted.internet import reactor\n",
    "import math\n",
    "import os.path\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil import parser\n",
    "from tqdm import tqdm_notebook #(Optional, used for progress-bars)\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "idx = pd.IndexSlice\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client login to binance.us\n",
    "binance_client = Client(getenv('binance_api'), getenv('binance_secret'))\n",
    "binsizes = {\"1m\": 1, \"5m\": 5, \"1h\": 60, \"1d\": 1440}\n",
    "batch_size = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes_of_new_data(symbol, kline_size, data, source):\n",
    "    if len(data) > 0:  old = parser.parse(data[\"timestamp\"].iloc[-1])\n",
    "    elif source == \"binance\": old = datetime.strptime('1 Jan 2017', '%d %b %Y')\n",
    "    if source == \"binance\": new = pd.to_datetime(binance_client.get_klines(symbol=symbol, interval=kline_size)[-1][0], unit='ms')\n",
    "    return old, new\n",
    "\n",
    "def get_all_binance(symbol, kline_size, save = False):\n",
    "    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
    "    if os.path.isfile(filename): data_df= pd.read_csv(filename)\n",
    "    else: data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"binance\")\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    if oldest_point == datetime.strptime('1 Jan 2017', '%d %b %Y'): print('Downloading all available %s data for %s. Be patient..!' % (kline_size, symbol))\n",
    "    else: print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data.' % (delta_min, symbol, available_data, kline_size))\n",
    "    klines = binance_client.get_historical_klines(symbol, kline_size, oldest_point.strftime(\"%d %b %Y %H:%M:%S\"), newest_point.strftime(\"%d %b %Y %H:%M:%S\"))\n",
    "    for line in klines:\n",
    "        del line[5:]\n",
    "    data = pd.DataFrame(klines, columns = ['timestamp', 'open', 'high', 'low', 'close'])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    data['symbol'] = symbol\n",
    "    if len(data_df) > 0:\n",
    "        temp_df = pd.DataFrame(data)\n",
    "        data_df = data_df.append(temp_df)\n",
    "    else: data_df = data\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save: data_df.to_csv(filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid intervals - 1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\n",
    "# saves all files in /data directory\n",
    "binance_symbols = []\n",
    "tickers = binance_client.get_all_tickers()\n",
    "for item in tickers:\n",
    "        binance_symbols.append(item['symbol'])\n",
    "for symbol in binance_symbols:\n",
    "    get_all_binance(symbol, '1d', save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globbed_files = glob.glob(\"*.csv\") #creates a list of all csv files\n",
    "\n",
    "data = [] # pd.concat takes a list of dataframes as an agrument\n",
    "for csv in globbed_files:\n",
    "    frame = pd.read_csv(csv)\n",
    "    frame['symbol'] = os.path.basename(csv)\n",
    "    data.append(frame)\n",
    "\n",
    "combined_data = pd.concat(data, ignore_index=True) #dont want pandas to try an align row indexes\n",
    "combined_data.to_csv('combined_data.csv', index=False, encoding='utf-8-sig') #export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_data.csv')\n",
    "df['symbol'] = [x.split(\"-\")[0] for x in df['symbol']]\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df = df[['symbol', 'close']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-06-01'\n",
    "end_date = '2021-02-01'\n",
    "mask = (df.index > start_date) & (df.index <= end_date)\n",
    "df = df.loc[mask]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = len(df.index)\n",
    "counts = df['symbol'].value_counts()\n",
    "df = df[~df['symbol'].isin(counts[counts < limit].index)]\n",
    "df = df[df['close'].notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.pivot_table(index='timestamp', columns='symbol', values='close')\n",
    "df.columns.name = None\n",
    "df = df[df['ETHBTC'].notna()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation to get the basic idea about the relationship\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "sns.heatmap(df.pct_change().corr(method ='pearson'), ax=ax, cmap='coolwarm', annot=True, fmt=\".2f\") #spearman\n",
    "ax.set_title('Assets Correlation Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " corr_df = df.corr(method='pearson')\n",
    " #reset symbol as index (rather than 0-X)\n",
    " corr_df.head().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #take the bottom triangle since it repeats itself\n",
    " mask = np.zeros_like(corr_df)\n",
    " mask[np.triu_indices_from(mask)] = True\n",
    " #generate plot\n",
    " sns.heatmap(corr_df, cmap='RdYlGn', vmax=1.0, vmin=-1.0 , mask = mask, linewidths=2.5)\n",
    " plt.yticks(rotation=0) \n",
    " plt.xticks(rotation=90) \n",
    " plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python39164bit90a65254d6da4f0d8e4e5fb2b89137a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}